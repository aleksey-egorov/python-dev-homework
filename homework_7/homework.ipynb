{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Домашнее задание</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "\n",
    "- Лекция Coursera: https://ru.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression\n",
    "- Статья на Хабре: https://habrahabr.ru/company/io/blog/265007/\n",
    "- Книжка ISLR, 4 глава: http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf\n",
    "- Логистическая регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/\n",
    "- Линейная регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm # interactive progress bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Знакомство с данными\n",
    "Данные представляют собой выборку отзывов о еде с сайта Амазон. Для них проставлены метки -- положительный или отрицательный отзыв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110163, 3)\n"
     ]
    }
   ],
   "source": [
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50074\n",
       "1    0.49926\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Prediction.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что классы сбалансированы. Можем оценивать качество модели по метрике ```accuracy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239071</td>\n",
       "      <td>Michigan Cherries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466160</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397133</td>\n",
       "      <td>Ovaltine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297146</td>\n",
       "      <td>~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292685</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID    Reviews_Summary  Prediction\n",
       "0  239071  Michigan Cherries           1\n",
       "1  466160      Great Product           1\n",
       "2  397133           Ovaltine           1\n",
       "3  297146                  ~           1\n",
       "4  292685           Love it!           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110158</th>\n",
       "      <td>486256</td>\n",
       "      <td>Terrible!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110159</th>\n",
       "      <td>199050</td>\n",
       "      <td>Cheap Coffee, No Banana Flavor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110160</th>\n",
       "      <td>278179</td>\n",
       "      <td>Not as described</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110161</th>\n",
       "      <td>87500</td>\n",
       "      <td>Tastes like a squirt of toothpaste mixed into ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110162</th>\n",
       "      <td>121963</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                    Reviews_Summary  Prediction\n",
       "110158  486256                                          Terrible!           0\n",
       "110159  199050                     Cheap Coffee, No Banana Flavor           0\n",
       "110160  278179                                   Not as described           0\n",
       "110161   87500  Tastes like a squirt of toothpaste mixed into ...           0\n",
       "110162  121963                                       Disappointed           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------\n",
    "## 2. Извлечение признаков\n",
    "Для решения задачи классификации необходимо преобразовать каждый отзыв (документ) в вектор. Размерность данного вектора будет равна количеству слов используемых в корпусе (все документы). Каждая координата соответствует слову, значение в координате равно количеству раз, слово используется в документе. \n",
    "\n",
    "Для решения данной задачи напишем код, который преобразовывает матрицу документов в численную матрицу.\n",
    "\n",
    "Дополнительная информация:\n",
    "\n",
    "- Подробнее про векторное представление документов: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "- Разряженные матрицы: http://www.scipy-lectures.org/advanced/scipy_sparse/\n",
    "- Трансформер: http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage\n",
    "- Подробнее про разреженные матрицы: http://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html\n",
    "- Hashing trick: https://en.wikipedia.org/wiki/Feature_hashing\n",
    "\n",
    "Помните, что все эти трансформеры возвращают ```sparse```-матрицы. Учитывая это и то, что линейные модели достаточно хорошо масштабируются на большое количество фич, можно смело ставить ```n_features``` 1000+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summaries = list(train_df['Reviews_Summary'].values)\n",
    "review_summaries = [l.lower() for l in review_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michigan cherries', 'great product', 'ovaltine', '~', 'love it!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Преобразуем ```review_summaries``` с помощью ```TfidfVectorizer```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfed = vectorizer.fit_transform(review_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sample= (77114, 16230) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "x_sample= (33049, 16230) <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksey/anaconda3/envs/otus-python-dev/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = tfidfed\n",
    "y = train_df.Prediction.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "print (\"x_sample=\", X_train.shape, type(X_train))\n",
    "print (\"x_sample=\", X_test.shape, type(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия -- линейный классификатор, который очень часто используется на практике, например, в кредитном скоринге. Преимущества этой модели -- скорость обучения и предсказания (даже при сотнях тысяч фичей) а также интепретируемость: важные признаки имеют бОльшие по модулю веса. \n",
    "\n",
    "При этом отрицательные веса говорят, что фича важна для определения класса 0, а положительные -- для определения класса 1. Это можно понять, если вспомнить, что разделяющая поверхность линейных моделей, это $w^Tx = 0$, а значение алгоритма есть $a(x) = sign(w^Tx)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем предсказывать сентимент, подготовим данные и сделаем валидационную выборку. При этом нужно оценивать качество модели не по обучающей выборке, а по валидационной. Иначе вы переобучитесь, когда будете тюнить гиперпараметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** Реализуйте код в модуле ```dmia.classifiers.logistic_regression```.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmia.gradient_check import *\n",
    "from dmia.classifiers.logistic_regression import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой ячейке вы можете проверить, правильно ли у вас все работает, прежде чем обучать модель на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sample= (20, 16230) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "dw= (20, 20)\n",
      "pred= (20, 1)\n",
      "x_sample=   (0, 13137)\t0.7988042720484626\n",
      "  (0, 6163)\t0.6015910030553363\n",
      "  (1, 5061)\t0.5880765598593313\n",
      "  (1, 2118)\t0.42492948291434945\n",
      "  (1, 15901)\t0.5813549719767702\n",
      "  (1, 7484)\t0.36827610681667455\n",
      "  (2, 9599)\t0.7162490493976857\n",
      "  (2, 503)\t0.697844752962227\n",
      "  (3, 2907)\t0.5806237332494576\n",
      "  (3, 4568)\t0.49924450725292735\n",
      "  (3, 14737)\t0.4543562911061198\n",
      "  (3, 15596)\t0.3267706655746155\n",
      "  (3, 14324)\t0.316878991442251\n",
      "  (4, 5968)\t0.7051434301535586\n",
      "  (4, 7446)\t0.6356174264485979\n",
      "  (4, 14201)\t0.3142661771590044\n",
      "  (5, 10152)\t0.7442963069722491\n",
      "  (5, 11617)\t0.5697980603537367\n",
      "  (5, 11191)\t0.34835783017551203\n",
      "  (6, 535)\t0.9288371721709284\n",
      "  (6, 14201)\t0.37048820169273033\n",
      "  (7, 1099)\t0.6007334553838917\n",
      "  (7, 15560)\t0.5811711699730574\n",
      "  (7, 14140)\t0.4312973596805265\n",
      "  (7, 14335)\t0.3396203384770766\n",
      "  :\t:\n",
      "  (14, 9445)\t0.36563498597649813\n",
      "  (14, 4305)\t0.4310493681014287\n",
      "  (15, 14252)\t0.8617230106306555\n",
      "  (15, 9511)\t0.5073790032605204\n",
      "  (16, 9904)\t0.6329672731236463\n",
      "  (16, 5801)\t0.47748988696383454\n",
      "  (16, 7602)\t0.4841324908477986\n",
      "  (16, 8436)\t0.3700967039939509\n",
      "  (17, 13200)\t0.5818407557543603\n",
      "  (17, 15943)\t0.5215323291677013\n",
      "  (17, 14395)\t0.3223475698120995\n",
      "  (17, 2990)\t0.34820428347269117\n",
      "  (17, 15816)\t0.40535316180290304\n",
      "  (18, 8264)\t0.4359950493632186\n",
      "  (18, 8403)\t0.40953894963829907\n",
      "  (18, 7597)\t0.31975639913383336\n",
      "  (18, 1171)\t0.3286834798332088\n",
      "  (18, 7515)\t0.40793882519874886\n",
      "  (18, 10006)\t0.2676545401515579\n",
      "  (18, 1372)\t0.33743478475860494\n",
      "  (18, 9921)\t0.20477319998292356\n",
      "  (18, 9445)\t0.19509445300420722\n",
      "  (19, 6175)\t0.663641387834516\n",
      "  (19, 549)\t0.663641387834516\n",
      "  (19, 14362)\t0.345195910616211\n",
      "clf.w= (16231,)\n",
      "grad= [<20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>\n",
      " <20x16231 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 98 stored elements in Compressed Sparse Row format>]\n",
      "dw= (20, 20)\n",
      "pred= (20, 1)\n",
      "dw= (20, 20)\n",
      "pred= (20, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4737 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a4fb24ee1878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_biases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrad_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_check_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/python-dev-homework/homework_7/dmia/gradient_check.py\u001b[0m in \u001b[0;36mgrad_check_sparse\u001b[0;34m(f, x, analytic_grad, num_checks)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mgrad_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxph\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxmh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mgrad_analytic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalytic_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mrel_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_numerical\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_analytic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_numerical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_analytic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'numerical: %s analytic: %s, relative error: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_numerical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_analytic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4737 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "X_train_sample = X_train[:20]\n",
    "y_train_sample = y_train[:20]\n",
    "clf = LogisticRegression()\n",
    "clf.w = np.random.randn(X_train_sample.shape[1]+1) * 2\n",
    "\n",
    "print (\"x_sample=\", X_train_sample.shape, type(X_train_sample))\n",
    "loss, grad = clf.loss(LogisticRegression.append_biases(X_train_sample), y_train_sample, 0.0)\n",
    "\n",
    "print (\"x_sample=\", X_train_sample)\n",
    "print (\"clf.w=\", clf.w.shape)\n",
    "print (\"grad=\", sum(grad))\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "f = lambda w: clf.loss(LogisticRegression.append_biases(X_train_sample), y_train_sample, 0.0)[0]\n",
    "\n",
    "grad_numerical = grad_check_sparse(f, clf.w, grad, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите свою модель на ```X_train, y_train```.\n",
    "\n",
    "Для начала можете взять параметры по умолчанию, и найти оптимальные используя валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.train(X_train, y_train, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Train f1-score = %.3f\" % accuracy_score(y_train, clf.predict(X_train)))\n",
    "print (\"Test f1-score = %.3f\" % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем кривые обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "num_iters = 1000\n",
    "\n",
    "for i in tqdm.trange(num_iters):\n",
    "    # Сделайте один шаг градиентного спуска с помощью num_iters=1\n",
    "    clf.train(X_train, y_train, learning_rate=1.0, num_iters=1, batch_size=256, reg=1e-3)\n",
    "    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(train_scores, 'r', test_scores, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Задание\n",
    "\n",
    "* Обучим нашу модель **на всех данных**, преобразовав их через ```TfidfVectorizer``` с ```max_features=3000```.\n",
    "\n",
    "* Параметры модели ```learning_rate=1.0, num_iters=1000, batch_size=256, reg=1e-3``` и выведем первые 5 самых важных фичей для класса 1 и 5 фичей для класса 0. Убедимся, что они коррелируют с вашей интуицией о хороших/плохих отзывах. \n",
    "\n",
    "**Hint:** зная индекс фичи, само слово вы можете получить, используя метод ```vectorizer.get_feature_names()```.\n",
    "\n",
    "**Hint:** ```np.argsort```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X = vectorizer.fit_transform(review_summaries)\n",
    "y = train_df.Prediction.values\n",
    "clf = LogisticRegression()\n",
    "clf.train(X, y, verbose=True, learning_rate=1.0, num_iters=1000, batch_size=256, reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получите индексы фичей\n",
    "pos_features = np.argsort(clf.w)[-5:]\n",
    "neg_features = np.argsort(clf.w)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите слова\n",
    "fnames = vectorizer.get_feature_names()\n",
    "print [fnames[p] for p in pos_features]\n",
    "print [fnames[n] for n in neg_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение с sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите такую же модель, но из пакета ```sklearn.linear_model``` и убедитесь, что ваша имплементация ничем не хуже (ну или почти не хуже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(n_iter=1000, random_state=42, loss=\"log\", penalty=\"l2\", alpha=1e-3, eta0=1.0, learning_rate=\"constant\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
